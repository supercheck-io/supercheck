# Local Development Docker Compose - Simplified
# Use this for local development
#
# Access:
# - Main app: http://localhost:3000
# - Status pages: http://localhost:3000/status/{subdomain}
# - Example: http://localhost:3000/status/abc123
#
# Status pages also accessible via middleware rewriting if needed

# YAML anchors for shared configuration
x-common-env: &common-env # Database Configuration
  DATABASE_URL: postgresql://postgres:postgres@postgres:5432/supercheck
  DB_HOST: postgres
  DB_PORT: 5432
  DB_USER: postgres
  DB_PASSWORD: postgres
  DB_NAME: supercheck

  # Redis Configuration
  REDIS_HOST: redis
  REDIS_PORT: 6379
  REDIS_PASSWORD: supersecure-redis-password-change-this
  REDIS_URL: redis://:supersecure-redis-password-change-this@redis:6379

  # App Configuration
  # IMPORTANT: Use localhost:3000 for local development
  NEXT_PUBLIC_APP_URL: http://localhost:3000
  # Runtime env vars for middleware (middleware can't access NEXT_PUBLIC_ vars at runtime)
  APP_URL: http://localhost:3000
  STATUS_PAGE_DOMAIN: supercheck.io
  STATUS_PAGE_BASE_DOMAIN: ${STATUS_PAGE_BASE_DOMAIN:-localhost}
  BETTER_AUTH_URL: http://localhost:3000
  BETTER_AUTH_SECRET: ${BETTER_AUTH_SECRET:-CHANGE_THIS_GENERATE_32_CHAR_HEX}
  NODE_ENV: development
  RUNNING_CAPACITY: 2 # Single worker replica Ã— 2 concurrent runs for local dev
  QUEUED_CAPACITY: 10
  MAX_CONCURRENT_EXECUTIONS: 2 # Mirrors production default; bump replicas instead of this value
  TEST_EXECUTION_TIMEOUT_MS: 120000
  JOB_EXECUTION_TIMEOUT_MS: 900000
  K6_TEST_EXECUTION_TIMEOUT_MS: 3600000
  K6_JOB_EXECUTION_TIMEOUT_MS: 3600000

  # AWS S3 / MinIO Configuration
  AWS_REGION: us-east-1
  AWS_ACCESS_KEY_ID: minioadmin
  AWS_SECRET_ACCESS_KEY: minioadmin
  S3_ENDPOINT: http://minio:9000
  S3_JOB_BUCKET_NAME: playwright-job-artifacts
  S3_TEST_BUCKET_NAME: playwright-test-artifacts
  S3_MONITOR_BUCKET_NAME: playwright-monitor-artifacts
  S3_STATUS_BUCKET_NAME: playwright-status-artifacts
  S3_PERFORMANCE_BUCKET_NAME: supercheck-performance-artifacts
  S3_FORCE_PATH_STYLE: true
  S3_OPERATION_TIMEOUT: 10000
  S3_MAX_RETRIES: 3

  # Notification Channel Limits
  NEXT_PUBLIC_MAX_JOB_NOTIFICATION_CHANNELS: 10
  NEXT_PUBLIC_MAX_MONITOR_NOTIFICATION_CHANNELS: 10

  # Playwright Configuration
  PLAYWRIGHT_HEADLESS: true
  PLAYWRIGHT_RETRIES: 1
  PLAYWRIGHT_TRACE: retain-on-failure
  PLAYWRIGHT_SCREENSHOT: only-on-failure
  PLAYWRIGHT_VIDEO: retain-on-failure

  # Browser support
  ENABLE_FIREFOX: false
  ENABLE_WEBKIT: false
  ENABLE_MOBILE: false

  # Monitor Results Cleanup
  MONITOR_CLEANUP_ENABLED: true
  MONITOR_CLEANUP_CRON: "0 2 * * *"
  MONITOR_RETENTION_DAYS: 30
  MONITOR_CLEANUP_BATCH_SIZE: 1000
  MONITOR_PRESERVE_STATUS_CHANGES: true
  MONITOR_CLEANUP_SAFETY_LIMIT: 1000000

  # Job Runs Cleanup
  JOB_RUNS_CLEANUP_ENABLED: false
  JOB_RUNS_CLEANUP_CRON: "0 3 * * *"
  JOB_RUNS_RETENTION_DAYS: 90
  JOB_RUNS_CLEANUP_BATCH_SIZE: 100
  JOB_RUNS_CLEANUP_SAFETY_LIMIT: 10000

  # Playground Artifacts Cleanup
  PLAYGROUND_CLEANUP_ENABLED: true
  PLAYGROUND_CLEANUP_CRON: "0 */12 * * *"
  PLAYGROUND_CLEANUP_MAX_AGE_HOURS: 24

  # Security Configuration
  SECRET_ENCRYPTION_KEY: ${SECRET_ENCRYPTION_KEY:-CHANGE_THIS_GENERATE_32_CHAR_HEX}

  # Better Auth Admin Configuration
  MAX_PROJECTS_PER_ORG: 10
  DEFAULT_PROJECT_NAME: Default Project

  # SMTP Email Configuration
  SMTP_HOST: smtp.resend.com
  SMTP_PORT: 587
  SMTP_USER: resend
  SMTP_PASSWORD: your-smtp-password-change-this-in-production
  SMTP_SECURE: false
  SMTP_FROM_EMAIL: notification@example.com

  # AI Fix Feature Configuration
  AI_PROVIDER: openai
  AI_MODEL: gpt-4o-mini
  OPENAI_API_KEY: your-openai-api-key-here
  AI_TIMEOUT_MS: 90000
  AI_MAX_RETRIES: 2
  AI_TEMPERATURE: 0.1

  # Observability Configuration
  USE_CLICKHOUSE_DIRECT: ${USE_CLICKHOUSE_DIRECT:-true}
  CLICKHOUSE_URL: ${CLICKHOUSE_URL:-http://clickhouse-observability:8123}
  CLICKHOUSE_USER: ${CLICKHOUSE_USER:-default}
  CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-}
  CLICKHOUSE_DATABASE: ${CLICKHOUSE_DATABASE:-default}

  # OpenTelemetry Configuration
  ENABLE_WORKER_OBSERVABILITY: ${ENABLE_WORKER_OBSERVABILITY:-true}
  OTEL_EXPORTER_OTLP_ENDPOINT: ${OTEL_EXPORTER_OTLP_ENDPOINT:-http://otel-collector:4317}
  OTEL_EXPORTER_OTLP_HTTP_ENDPOINT: ${OTEL_EXPORTER_OTLP_HTTP_ENDPOINT:-http://otel-collector:4318/v1/traces}
  OTEL_EXPORTER_OTLP_PROTOCOL: ${OTEL_EXPORTER_OTLP_PROTOCOL:-http}
  OTEL_SERVICE_NAME: ${OTEL_SERVICE_NAME:-supercheck}
  OTEL_LOG_LEVEL: ${OTEL_LOG_LEVEL:-error}
  OTEL_TRACE_SAMPLE_RATE: ${OTEL_TRACE_SAMPLE_RATE:-1.0}

services:
  # App (Next.js Frontend)
  app:
    build:
      context: ./app
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    env_file:
      - .env.local
    environment:
      <<: *common-env
    volumes:
      # Mount TypeScript definitions for Monaco Editor in playground
      - ./app/public/supercheck.d.ts:/app/public/supercheck.d.ts:ro
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD",
          "node",
          "-e",
          "const http = require('http'); const req = http.request({hostname: 'localhost', port: 3000, path: '/api/health', timeout: 5000}, (res) => process.exit(res.statusCode < 400 ? 0 : 1)); req.on('error', () => process.exit(1)); req.end();",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    networks:
      - supercheck-network
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
        reservations:
          cpus: "0.5"
          memory: 1G

  # Worker (NestJS Runner)
  worker:
    build:
      context: ./worker
      dockerfile: Dockerfile
    env_file:
      - .env.local
    environment:
      <<: *common-env
    volumes:
      - worker-playwright-reports:/app/playwright-reports
      - worker-reports:/app/report
      - type: tmpfs
        target: /dev/shm
        tmpfs:
          size: 8589934592 # 8GB shared memory
    depends_on:
      postgres:
        condition: service_healthy
      app:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD",
          "node",
          "-e",
          "const http = require('http'); const req = http.request({hostname: 'localhost', port: 3001, path: '/health', timeout: 5000}, (res) => process.exit(res.statusCode === 200 ? 0 : 1)); req.on('error', () => process.exit(1)); req.end();",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - supercheck-network
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: "1.5" # Keep local worker responsive without starving the host machine
          memory: 3G # Enough for two Playwright sessions with tracing in dev
        reservations:
          cpus: "0.75"
          memory: 2048M
    sysctls:
      - net.core.somaxconn=4096
    ulimits:
      nproc: 65535
      nofile:
        soft: 1048576
        hard: 1048576
      memlock:
        soft: -1
        hard: -1
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - SYS_ADMIN

  # PostgreSQL Database
  postgres:
    image: postgres:18
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=supercheck
    volumes:
      - postgres-data:/var/lib/postgresql
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 30s
    networks:
      - supercheck-network
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1.5G
        reservations:
          cpus: "0.5"
          memory: 1G

  # Redis (for job queues)
  redis:
    image: redis:8
    environment:
      - REDIS_PASSWORD=supersecure-redis-password-change-this
    command: sh -c "rm -rf /data/* && redis-server --requirepass \"supersecure-redis-password-change-this\" --maxmemory 512mb --maxmemory-policy noeviction --save '' --appendonly no --protected-mode yes --bind 0.0.0.0 --tcp-keepalive 300"
    volumes:
      - redis-data:/data
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD",
          "redis-cli",
          "-a",
          "supersecure-redis-password-change-this",
          "ping",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - supercheck-network
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M

  # MinIO (S3-compatible storage)
  minio:
    image: minio/minio:latest
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - supercheck-network
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 1G
        reservations:
          cpus: "0.25"
          memory: 512M

  # ============================================================================
  # OBSERVABILITY STACK
  # ============================================================================

  # ClickHouse - Time-series database for observability data
  clickhouse-observability:
    image: clickhouse/clickhouse-server:25.5.6
    container_name: clickhouse-observability
    hostname: clickhouse
    environment:
      - CLICKHOUSE_SKIP_USER_SETUP=1
      - CLICKHOUSE_DEFAULT_REPLICATION=false
    ports:
      - "9001:9000"
      - "8124:8123"
    volumes:
      - signoz-clickhouse:/var/lib/clickhouse
      - ./otel/deploy/common/clickhouse/config.xml:/etc/clickhouse-server/config.xml:ro
      - ./otel/deploy/common/clickhouse/users.xml:/etc/clickhouse-server/users.xml:ro
      - ./otel/deploy/common/clickhouse/custom-function.xml:/etc/clickhouse-server/custom-function.xml:ro
      - ./otel/deploy/common/clickhouse/cluster-standalone.xml:/etc/clickhouse-server/config.d/cluster.xml:ro
      - ./otel/deploy/common/clickhouse/user_scripts:/var/lib/clickhouse/user_scripts:ro
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "0.0.0.0:8123/ping"]
      interval: 30s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    networks:
      - supercheck-network
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
        reservations:
          cpus: "0.5"
          memory: 1G

  # Schema Migrator - Sets up ClickHouse tables for observability data
  schema-migrator:
    image: signoz/signoz-schema-migrator:v0.129.8
    container_name: schema-migrator
    command:
      - sync
      - --dsn=tcp://clickhouse:9000
      - --cluster-name=cluster
      - --up=
    environment:
      - CLICKHOUSE_CLUSTER=cluster
    depends_on:
      clickhouse-observability:
        condition: service_healthy
    restart: on-failure
    networks:
      - supercheck-network

  # OpenTelemetry Collector - Receives and processes telemetry data
  otel-collector:
    image: signoz/signoz-otel-collector:v0.129.8
    container_name: otel-collector
    hostname: otel-collector
    command:
      - --config=/etc/otel/config.yaml
      - --feature-gates=-pkg.translator.prometheus.NormalizeName
    volumes:
      - ./otel/deploy/docker/otel-collector-config.yaml:/etc/otel/config.yaml:ro
    environment:
      - OTEL_RESOURCE_ATTRIBUTES=host.name=supercheck-host,os.type=linux
    ports:
      - "4317:4317"
      - "4318:4318"
    depends_on:
      clickhouse-observability:
        condition: service_healthy
      schema-migrator:
        condition: service_completed_successfully
    healthcheck:
      test:
        [
          "CMD",
          "bash",
          "-c",
          "</dev/tcp/127.0.0.1/13133",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - supercheck-network
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M

volumes:
  postgres-data:
    driver: local
  redis-data:
    driver: local
  minio-data:
    driver: local
  worker-playwright-reports:
    driver: local
  worker-reports:
    driver: local
  signoz-clickhouse:
    driver: local

networks:
  supercheck-network:
    driver: bridge
